---
title: Big Data Processing Course Introduction
author: Guillaume Eynard-Bontemps, CNES (Centre National d'Etudes Spatiales - French Space Agency)
date: 2020-11-15
background-image: /images/background-logo.png 
---

# Welcome

## Course Overview

Title
- ARTIFICIAL INTELLIGENCE & BUSINESS TRANSFORMATION
- BLOC 1 : ARTIFICIAL INTELLIGENCE INTERNALS
- AIBT103_Big Data Processing

Goals

Evaluation.

## About myself

- Guillaume Eynard-Bontemps
- CNES
- 5 years on Hadoop
- 6 years on HPC
- 3 years using Dask

# Program

## Day 1: Big Data, Distributed Computing and Spark

- Introduction to Big Data and its ecosystem (1h)
  - What is Big Data?
  - Legacy “Big Data” ecosystem
  - Big Data use cases
  - Big Data to Machine Learning
- Big Data platforms (2h)
  - Hadoop: HDFS and MapReduce, Data distribution and chunking
  - From HPC to Big Data to Cloud and High Performance Data Analytics 
  - BI vs Big Data
  - Hadoop legacy: Spark, Dask, Object Storage, File format, Datalakes
  - Distributed programming: Hadoop vs HPC vs Cloud
  - Distributed Machine Learning, GPGPU computing
- Spark Introduction (1h)
- Play with MapReduce through Spark (small dataset) (2h)
  - Notebook

## Day 2: Cloud Computing and Kubernetes

- Cloud computing (2h)
  - Virtualization and cloud computing: Different approaches, Economical models, Technical benefits, cloud engines
  - IaaS, PaaS, CaaS, SaaS, Object Storage
  - New Data processing standard: object store and compute as a service
- First interaction with Google Cloud, how to get a server? (1h)
  - TP through Google console
- Container as a Service (1.5h)
  - Container, TP Docker?
  - Kubernetes
  - Processing platform as a Service (Databricks, Coiled)
- TP Deploy Data processing platform on the Cloud based on Kubernetes and Dask (2h)
  - DaskHub or Dask Kubernetes or Pangeo

## Day 3: Python ecosystem for data processing and Dask

- The rise of the Python ecosystem for Data Processing (1.5h)
  - Pydata stack (Pandas, Numpy, Dask)
  - Machine and Deep Learning (Sickit Learn, TensorFlow Pytorch)
  - Jupyter notebooks, Binder, Google Colab
- Pandas tutorial (1h)
- Dask Presentation (1h)
- Dask Tutorial (2h): notebook
- Pangeo tutorial or finish deploying your computing platform (1h)

## Day 4: Evaluation

- Prerequisite: Pangeo platform deployed before
- Clean big amounts of data using Dask in the cloud (3h),
- Train machine learning models in parallel (hyper parameter search) (3h).

