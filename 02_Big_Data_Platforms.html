<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Guillaume Eynard-Bontemps, CNES (Centre National d’Etudes Spatiales - French Space Agency)">
  <meta name="dcterms.date" content="2020-11-15">
  <title>Big Data Platforms</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/theme/solarized.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Big Data Platforms</h1>
  <p class="author">Guillaume Eynard-Bontemps, CNES (Centre National d’Etudes Spatiales - French Space Agency)</p>
  <p class="date">2020-11-15</p>
</section>

<section>
<section id="hadoop" class="title-slide slide level1">
<h1>Hadoop</h1>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<p>What is Hadoop?</p>
<p>Open source framework supported by Apache foundation:</p>
<ul>
<li>Store and process massive amount of data</li>
<li>In a distributed way</li>
<li>On “commodity” hardware (i.e. not expensive)</li>
</ul>
</section>
<section id="a-complex-ecosystem" class="slide level2">
<h2>A complex ecosystem</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img data-src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2016/10/HADOOP-ECOSYSTEM-Edureka.png" style="width:80.0%" alt="Hadoop ecosystem" /><figcaption aria-hidden="true">Hadoop ecosystem</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<p>Numerous Apache Software Foundation projects:</p>
<ul>
<li>Each covering a specific functionnality</li>
<li>With their own developer community</li>
<li>And their own development cycle</li>
</ul>
<p>Hadoop distributions! - Cloudera/Horthonworks (2018 fusion) - MapR - Others smaller</p>
</div>
</div>
</section>
<section id="hdfs-and-mapreduce-principles" class="slide level2">
<h2>HDFS and MapReduce principles</h2>
<h3 id="two-main-components-of-hadoop">Two main components of Hadoop</h3>
<ul>
<li>Distributed Software Defined Storage: HDFS (Hadoop Distributed File System) <img data-src="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/images/hdfs-logo.jpg" height="50" /></li>
<li>Distributed Data Processing: MapReduce <img data-src="https://www.pikpng.com/pngl/m/533-5331939_hadoop-apache-org-hadoop-map-reduce-logo-png.png" height="50" /></li>
</ul>
<h3 id="principles">Principles</h3>
<ul>
<li>Split and store data on a cluster of servers (with local storage)</li>
<li>Process data localy (on the server which owns it)</li>
<li>Horizontal scalability: add or remove machines, on the fly, for compute or storage</li>
</ul>
</section>
<section id="hadoop-cluster-components" class="slide level2" data-background-image="https://pbs.twimg.com/media/EKzU0wMWsAAkKLc.jpg" data-background-opacity="0.4">
<h2 data-background-image="https://pbs.twimg.com/media/EKzU0wMWsAAkKLc.jpg" data-background-opacity="0.4">Hadoop cluster components</h2>
<ul>
<li>CLuster of “commodity” servers</li>
<li><strong>Shared Nothing</strong> architecture: only shared component is <em>standard</em> network</li>
<li>Each machine is a node which own both storage and compute</li>
</ul>
<p>Each cluster is composed of:</p>
<ul>
<li>Master nodes: handle metadata and knowledge of the whole infrastructure</li>
<li>Worker nodes:
<ul>
<li>Host distributed pieces of data</li>
<li>Execute data processing algorithm parts</li>
</ul></li>
</ul>
</section>
<section id="hadoop-story-from-google-to-spark" class="slide level2">
<h2>Hadoop story, from google to Spark</h2>
<figure>
<img data-src="https://static.packt-cdn.com/products/9781788999830/graphics/assets/4cf97ee3-8f90-4904-9094-dffd90bd066c.png" style="height:40.0%" alt="Hadoop history (Packt)" /><figcaption aria-hidden="true">Hadoop history (Packt)</figcaption>
</figure>
</section></section>
<section>
<section id="hdfs" class="title-slide slide level1">
<h1>HDFS</h1>

</section>
<section id="hdfs-basics" class="slide level2">
<h2>HDFS Basics</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="distributed-file-system">Distributed File System</h3>
<ul>
<li>Written in <strong>Java</strong></li>
<li>Allowing to <strong>store</strong> massive amounts of data,
<ul>
<li>structured or not,</li>
<li>on a machines cluster</li>
</ul></li>
<li>Extensible and portable</li>
<li>One of the first <strong>Software Defined Storage</strong>
<ul>
<li>(OK, Google was here first)</li>
</ul></li>
<li>In HDFS, data are of <strong>writen-once</strong> type (no inline modifications)</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="data-blocks">Data blocks</h3>
<ul>
<li>Data is <strong>splitted</strong> and <strong>distributed</strong>
<ul>
<li>among the Hadoop cluster</li>
</ul></li>
<li>Splitted into 128MB (default) <strong>blocks</strong></li>
<li>With a <strong>replication</strong> factor for preventing data loss
<ul>
<li>(3 replicas default)</li>
</ul></li>
<li>Hadoop 3: <strong>Erasure coding</strong>
<ul>
<li>similar durability as replication 3,</li>
<li>but <strong>only 50%</strong> volume increase</li>
<li>instead of 200%</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="hdfs-blocks-repartition" class="slide level2">
<h2>HDFS blocks repartition</h2>
<p><img data-src="images/HDFSBlocks.png" /></p>
</section>
<section id="hdfs-daemons" class="slide level2">
<h2>HDFS Daemons</h2>
<div class="columns">
<div class="column" style="width:60%;">
<h3 id="namenode">Namenode</h3>
<ul>
<li>Accountable for data locality and file system global namespace</li>
<li>Daemon on a dedicated server</li>
<li>Hosts metadata, create, remove, move files and folders</li>
<li>Knows nodes wich own the parts of a file</li>
<li>Needs to be replicated and secured (loss of metadata = loss of all data)</li>
</ul>
</div><div class="column" style="width:40%;">
<h3 id="datanode">Datanode</h3>
<ul>
<li>Stores and loads data blocks</li>
<li>Daemon on every worker nodes</li>
<li>Reading and writing of data</li>
<li>Creation and Deletion of blocks</li>
</ul>
</div>
</div>
</section>
<section id="hdfs-architecture" class="slide level2">
<h2>HDFS Architecture</h2>
<p><img data-src="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png" /></p>
</section></section>
<section>
<section id="map-reduce" class="title-slide slide level1">
<h1>Map Reduce</h1>

</section>
<section id="map-reduce-basics" class="slide level2">
<h2>Map Reduce Basics</h2>
<ul>
<li><strong>Functional</strong> language concept</li>
<li>Heavily used by Google for <strong>WWW indexing</strong></li>
<li><strong>Colocate</strong> data and processing (with Hadoop and others)</li>
<li>Automatic process <strong>ditribution</strong> on pieces of data (eager distribution)</li>
<li>Optimized for fast processing of <strong>huge datasets</strong></li>
<li><strong>Fault tolerant</strong>:
<ul>
<li>Data is replicated,</li>
<li>Individual task can be restarted anywhere</li>
</ul></li>
</ul>
</section>
<section id="wordcount-1.-storage" class="slide level2">
<h2>Wordcount (1. storage)</h2>
<p><img data-src="images/Wordcount1.png" style="background:white" /></p>
</section>
<section id="wordcount-2.-split" class="slide level2">
<h2>Wordcount (2. split)</h2>
<p><img data-src="images/Wordcount2.png" style="background:white" /></p>
</section>
<section id="wordcount-3.-map" class="slide level2">
<h2>Wordcount (3. map)</h2>
<p><img data-src="images/Wordcount3.png" style="background:white" /></p>
</section>
<section id="wordcount-4.-shuffle" class="slide level2">
<h2>Wordcount (4. shuffle)</h2>
<p><img data-src="images/Wordcount4.png" style="background:white" /></p>
</section>
<section id="wordcount-5.-reduce" class="slide level2">
<h2>Wordcount (5. reduce)</h2>
<p><img data-src="images/Wordcount5.png" style="background:white" /></p>
</section>
<section id="wordcount-6.-result" class="slide level2">
<h2>Wordcount (6. result)</h2>
<p><img data-src="images/Wordcount6.png" style="background:white" /></p>
</section>
<section id="yarn" class="slide level2">
<h2>YaRN</h2>
<ul>
<li>Yet Another Resource Negociator…</li>
<li>Introduced in Hadoop v2</li>
<li>Separation between
<ul>
<li>Resources scheduling and cluster state</li>
<li>Job execution and distribution</li>
</ul></li>
</ul>
<p><img data-src="images/YARN.png" style="width:40.0%" /> <img data-src="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif" style="width:40.0%" /></p>
</section></section>
<section>
<section id="datalakes" class="title-slide slide level1">
<h1>Datalakes</h1>

</section>
<section id="toward-a-new-data-management-model" class="slide level2">
<h2>Toward a new data management model</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="process-centric">Process centric</h3>
<ul>
<li>Structured Data</li>
<li>Internal sources</li>
<li>Important data only</li>
<li>Multiple copies</li>
</ul>
<p><img data-src="images/ProcessCentric.png" style="height:30.0%" /></p>
</div><div class="column" style="width:50%;">
<h3 id="data-centric">Data centric</h3>
<ul>
<li>Multiple types (structured, semi-structured, unstructured)</li>
<li>Multiple sources (internal, external)</li>
<li>Everything</li>
<li>One copy</li>
</ul>
<p><img data-src="images/DataCentric.png" style="height:30.0%" /></p>
</div>
</div>
</section>
<section id="host-and-process-different-kind-of-data" class="slide level2">
<h2>Host and process different kind of data</h2>
<p><img data-src="images/Datalake1.png" style="width:60.0%" /></p>
</section>
<section id="typical-architecture" class="slide level2">
<h2>Typical Architecture</h2>
<figure>
<img data-src="https://www.oreilly.com/library/view/architecting-data-lakes/9781492042518/assets/ardl_0201.png" style="width:80.0%" alt="Oreilly’s Datalake" /><figcaption aria-hidden="true">Oreilly’s Datalake</figcaption>
</figure>
</section>
<section id="cnes-datalake-infrastructure-example" class="slide level2">
<h2>CNES Datalake infrastructure example</h2>
<p><img data-src="images/CNESDatalake.png" style="width:60.0%" /></p>
</section></section>
<section>
<section id="from-hpc-to-big-data-to-cloud-and-high-performance-data-analytics" class="title-slide slide level1">
<h1>From HPC to Big Data to Cloud and High Performance Data Analytics</h1>

</section>
<section id="hpc-platform-story-and-use-case" class="slide level2">
<h2>HPC platform, story and use case</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>HPC = High Performance Computing</p>
</blockquote>
<ul>
<li>Firsts HPC platforms built in the 1960s</li>
<li>Mainly compute bounds algorithms</li>
<li>At first for Weather forcasting and Aerodynamic research</li>
<li>Structure modeling and fluid mecanics by discretization</li>
<li>Needs (needed?) high performance hardware (network, CPUs, storage)</li>
<li>Compute and storage are separated</li>
<li>Uses a resource scheduler</li>
</ul>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="http://www.idris.fr/media/images/jean-zay-annonce-01.jpg?id=web%3Aeng%3Ajean-zay%3Acpu%3Ajean-zay-cpu-hw-eng" alt="Jean-Zay supercomputer" /><figcaption aria-hidden="true">Jean-Zay supercomputer</figcaption>
</figure>
</div>
</div>
</section>
<section id="top500" class="slide level2">
<h2>TOP500</h2>
<table>
<thead>
<tr class="header">
<th>Rank</th>
<th>System</th>
<th>Cores</th>
<th>Rmax (TFlop/s)</th>
<th>Rpeak (TFlop/s)</th>
<th>Power (kW)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Supercomputer Fugaku - Japan</td>
<td>7,630,848</td>
<td>442,010.0</td>
<td>537,212.0</td>
<td>29,899</td>
</tr>
<tr class="even">
<td>2</td>
<td>Summit - United States</td>
<td>2,414,592</td>
<td>148,600.0</td>
<td>200,794.9</td>
<td>10,096</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Sierra - United States</td>
<td>1,572,480</td>
<td>94,640.0</td>
<td>125,712.0</td>
<td>7,438</td>
</tr>
<tr class="even">
<td>8</td>
<td>JUWELS Booster Module - Germany</td>
<td>449,280</td>
<td>44,120.0</td>
<td>70,980.0</td>
<td>1,764</td>
</tr>
<tr class="odd">
<td>21</td>
<td>PANGEA III - France</td>
<td>291,024</td>
<td>17,860.0</td>
<td>25,025.8</td>
<td>1,367</td>
</tr>
<tr class="even">
<td>92</td>
<td>Jean Zay - France</td>
<td>93,960</td>
<td>4,478.0</td>
<td>7,345.6</td>
<td></td>
</tr>
</tbody>
</table>
<p><a href="https://top500.org/lists/top500/list/2021/06/">Top 500 (june 2021)</a></p>
</section>
<section id="big-data-and-hadoop" class="slide level2">
<h2>Big Data and Hadoop</h2>
<ul>
<li>First platforms in the 2000’s</li>
<li>Mainly data bound algorithms</li>
<li>Limitation in standard ethernet network performances = data locality</li>
<li>At first for web indexing, or large amount of textual or tabular data analysis</li>
<li>Web giant problem, then banking or IT stuf</li>
<li>Use commodity hardware</li>
<li>Compute and storage colocated</li>
</ul>
</section>
<section id="hpda-convergence" class="slide level2">
<h2>HPDA convergence</h2>
<p><img data-src="images/HPDA.png" style="width:50.0%" /></p>
<ul>
<li>Hadoop world step to HPC: YaRN, equivalent to HPC resources scheduler</li>
<li>HPC step to Big Data: hardware not so specialized</li>
<li>Hadoop big limitation: non standard File System and compute and storage colocation</li>
<li>HPC big limitation: storage can be difficult to scale</li>
</ul>
</section>
<section id="cloud-computing-basics" class="slide level2">
<h2>Cloud computing basics</h2>
<p>Hence the cloud computing model…</p>
<ul>
<li>Compute resources separated from storage (but proximity is key)</li>
<li>Can host anything, at first not compute oriented</li>
<li>Object store model: Software Defined Storage as HDFS, specific interface (S3)</li>
<li>Horizontal scalability of compute AND storage</li>
<li>Resources on demand, mutualized between millions of users</li>
<li>Infinite resources like for user</li>
</ul>
</section>
<section id="distributed-programming-hadoop-vs-hpc-vs-cloud" class="slide level2">
<h2>Distributed programming: Hadoop vs HPC vs Cloud</h2>
<div class="columns">
<div class="column" style="width:33%;">
<h3 id="hadoop-1">Hadoop</h3>
<ul>
<li>Data bound algorithms</li>
<li>Statistics</li>
<li>Big volumes in input</li>
<li>Often small outputs</li>
<li>Can be used for computing problems, but not physical simulation</li>
</ul>
</div><div class="column" style="width:33%;">
<h3 id="hpc-mpi">HPC (MPI)</h3>
<ul>
<li>Compute bound algorithms</li>
<li>Small or medium amount of inputs,</li>
<li>Medium or big outputs (big simulations)</li>
<li>Can be used for data processing too (Dask)</li>
</ul>
</div><div class="column" style="width:33%;">
<h3 id="cloud">Cloud</h3>
<ul>
<li>Anything: services, storage bound, compute bound</li>
<li>Object store limitations for some HPC workflow</li>
<li>Or not anymore: HPC as a Service</li>
<li>Big Data as a Service too…</li>
</ul>
</div>
</div>
</section>
<section id="machine-learning-computations" class="slide level2">
<h2>Machine Learning Computations</h2>
<h3 id="machine-learning">Machine learning</h3>
<ul>
<li>Either lots of data in inputs</li>
<li>Or lots of models to train (hyperparameter search)</li>
<li>And of course data preprocessing</li>
<li>Big Data or HPC or Cloud</li>
</ul>
<h3 id="gpgpu">GPGPU</h3>
<ul>
<li>Specific hardware (expensive)</li>
<li>Really efficient for Deep Learning algorithms</li>
<li>Image processing, Language processing</li>
</ul>
</section></section>
<section>
<section id="bi-vs-big-data" class="title-slide slide level1">
<h1>BI vs Big Data</h1>

</section>
<section id="business-intelligence" class="slide level2">
<h2>Business Intelligence</h2>
<blockquote>
<p>Business intelligence (BI) comprises the strategies and technologies used by enterprises for the data analysis of business information.</p>
<p>BI technologies provide historical, current, and predictive views of business operations.</p>
</blockquote>
<p><em>Wikipedia</em></p>
<p>Business Intelligence <em>can</em> use Big Data ecosystems, but is more commonly considered something different.</p>
<p>https://medium.com/doctolib/data-engineers-are-no-longer-data-folks-d10d44712580 https://alphalyr.fr/blog/difference-bi-business-intelligence-big-data/</p>
</section>
<section id="classical-bi-key-points" class="slide level2">
<h2>Classical BI key points</h2>
<ul>
<li>Build data systems from Business questions</li>
<li>KPI and business decisions oriented</li>
<li>Data warehouse, mainframe = Big server with closed technology</li>
<li>Use structured data, like SQL databases,</li>
<li>Oriented towards Data Value</li>
</ul>
</section>
<section id="big-data-key-points" class="slide level2">
<h2>Big Data key points</h2>
<ul>
<li>Find insights from the data systems,</li>
<li>KPI and business of course, but many more use cases</li>
<li>Distributed architecture, lot of Open Source</li>
<li>Different toolset (Hadoop, Python),</li>
<li>Every data flavor, keep anything!</li>
<li>Data Volume, Variety, Velocity</li>
</ul>
</section></section>
<section>
<section id="hadoop-and-big-data-legacy" class="title-slide slide level1">
<h1>Hadoop and Big Data legacy</h1>

</section>
<section id="is-hadoop-dead" class="slide level2">
<h2>Is Hadoop dead?</h2>
<p>Not quite yet. Still <strong>used in many places</strong></p>
<div class="fragment">
<p>It grew up with <strong>web giants</strong>, producing a really rich and <strong>open source</strong> ecosystem</p>
</div>
<div class="fragment">
<p>But clearly the two main components (HDFS and MapReduce) are now <strong>deprecated</strong></p>
</div>
<div class="fragment">
<p>And have paved the way to better alternatives</p>
</div>
</section>
<section id="future-of-big-data" class="slide level2">
<h2>Future of Big Data</h2>
<p>Infrastructure: Private or public cloud, and HPC(DA) in some cases.</p>
<div class="fragment">
<p>HDFS? Object Storage!</p>
</div>
<div class="fragment">
<p>MapReduce? Spark, Dask.</p>
</div>
<div class="fragment">
<p>Chunked file format (SequenceFile)? Parquet, Zarr, Cloud optimized Geotiff.</p>
</div>
<div class="fragment">
<p>YaRN? HPC job scheduler, or Kubernetes</p>
</div>
<div class="fragment">
<h3 id="cloud-computing">Cloud Computing</h3>
</div>
</section></section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="https://unpkg.com/reveal.js@^4//plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: false,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

       // Parallax background image
       parallaxBackgroundImage: 'images/background-logo.png', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1800,

        height: 900,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.1,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
