<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Guillaume Eynard-Bontemps, CNES (Centre National d’Etudes Spatiales - French Space Agency)">
  <meta name="dcterms.date" content="2020-11-15">
  <title>Big Data Platforms, Hadoop and beyond</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reset.css">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@^4//dist/theme/solarized.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Big Data Platforms, Hadoop and beyond</h1>
  <p class="author">Guillaume Eynard-Bontemps, CNES (Centre National
d’Etudes Spatiales - French Space Agency)</p>
  <p class="date">2020-11-15</p>
</section>

<section>
<section id="hadoop" class="title-slide slide level1">
<h1>Hadoop</h1>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<p>What is Hadoop?</p>
<p>Open source framework supported by Apache foundation:</p>
<ul>
<li>Store and process massive amount of data</li>
<li>In a distributed way</li>
<li>On “commodity” hardware (i.e. not expensive)</li>
<li>Fault tolerant</li>
</ul>
</section>
<section id="a-complex-ecosystem" class="slide level2">
<h2>A complex ecosystem</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img
data-src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2016/10/HADOOP-ECOSYSTEM-Edureka.png"
style="width:80.0%" alt="Hadoop ecosystem" />
<figcaption aria-hidden="true">Hadoop ecosystem</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<p>Numerous Apache Software Foundation projects:</p>
<ul>
<li>Each covering a specific functionnality</li>
<li>With their own developer community</li>
<li>And their own development cycle</li>
</ul>
<p>Hadoop distributions!</p>
<ul>
<li>Cloudera/Horthonworks (2018 fusion)</li>
<li>MapR</li>
<li>Others smaller</li>
</ul>
</div>
</div>
</section>
<section id="hdfs-and-mapreduce-principles" class="slide level2">
<h2>HDFS and MapReduce principles</h2>
<h3 id="two-main-components-of-hadoop">Two main components of
Hadoop</h3>
<ul>
<li>Distributed Software Defined Storage: HDFS (Hadoop Distributed File
System) <img
data-src="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/images/hdfs-logo.jpg"
height="50" /></li>
<li>Distributed Data Processing: MapReduce <img
data-src="https://www.pikpng.com/pngl/m/533-5331939_hadoop-apache-org-hadoop-map-reduce-logo-png.png"
height="50" /></li>
</ul>
<h3 id="principles">Principles</h3>
<ul>
<li>Split and store data on a cluster of servers (with local
storage)</li>
<li>Process data localy (on the server which owns it)</li>
<li>Horizontal scalability: add or remove machines, on the fly, for
compute or storage</li>
<li>Fault tolerant</li>
</ul>
</section>
<section id="hadoop-cluster-components" class="slide level2"
data-background-image="https://pbs.twimg.com/media/EKzU0wMWsAAkKLc.jpg"
data-background-opacity="0.2">
<h2
data-background-image="https://pbs.twimg.com/media/EKzU0wMWsAAkKLc.jpg"
data-background-opacity="0.2">Hadoop cluster components</h2>
<ul>
<li>CLuster of “commodity” servers</li>
<li><strong>Shared Nothing</strong> architecture: only shared component
is <em>standard</em> network</li>
<li>Each machine is a node which own both storage and compute</li>
</ul>
<p>Each cluster is composed of:</p>
<ul>
<li>Master nodes: handle metadata and knowledge of the whole
infrastructure</li>
<li>Worker nodes:
<ul>
<li>Host distributed pieces of data</li>
<li>Execute data processing algorithm parts</li>
</ul></li>
</ul>
</section>
<section id="hadoop-story-from-google-to-spark" class="slide level2">
<h2>Hadoop story, from google to Spark</h2>
<figure>
<img data-src="images/Hadoop_Final.jpg" style="height:40.0%"
alt="Hadoop history" />
<figcaption aria-hidden="true">Hadoop history</figcaption>
</figure>
<p>Spark first version in 2014.</p>
</section>
<section id="quizz" class="slide level2">
<h2>Quizz</h2>
<p>What are the <strong>two</strong> building blocks of Hadoop ecosystem
(multiple choices)?</p>
<ul>
<li>Answer A: Oozie</li>
<li>Answer B: HDFS</li>
<li>Answer C: Map Reduce</li>
<li>Answer D: Servers</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_187">Answer link</a>
<em>Key: gf</em></p>
</section>
<section id="map-reduce-exercise" class="slide level2">
<h2>Map Reduce exercise</h2>
<p><a
href="https://www.learnpython.org/en/Map%2C_Filter%2C_Reduce">Learning
Python</a></p>
</section></section>
<section>
<section id="hdfs" class="title-slide slide level1">
<h1>HDFS</h1>

</section>
<section id="hdfs-basics" class="slide level2">
<h2>HDFS Basics</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="distributed-file-system">Distributed File System</h3>
<ul>
<li>Written in <strong>Java</strong></li>
<li>Allowing to <strong>store</strong> massive amounts of data,
<ul>
<li>structured or not,</li>
<li>on a cluster of machines</li>
</ul></li>
<li>Extensible and portable</li>
<li>One of the first <strong>Software Defined Storage</strong>
<ul>
<li>(OK, Google was here first)</li>
</ul></li>
<li>In HDFS, data are of <strong>writen-once</strong> type (no inline
modifications)</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="data-blocks">Data blocks</h3>
<ul>
<li>Data is <strong>splitted</strong> and <strong>distributed</strong>
<ul>
<li>among the Hadoop cluster</li>
</ul></li>
<li>Splitted into 128MB (default) <strong>blocks</strong></li>
<li>With a <strong>replication</strong> factor for preventing data loss
<ul>
<li>(3 replicas default)</li>
</ul></li>
<li>Hadoop 3: <strong>Erasure coding</strong>
<ul>
<li>similar or better durability as replication 3,</li>
<li>but <strong>only 50%</strong> volume increase (can be less or
more)</li>
<li>instead of 200%</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="hdfs-blocks-repartition" class="slide level2">
<h2>HDFS blocks repartition</h2>
<p><img data-src="images/HDFSBlocks.png" /></p>
</section>
<section id="hdfs-daemons" class="slide level2">
<h2>HDFS Daemons</h2>
<div class="columns">
<div class="column" style="width:60%;">
<h3 id="namenode">Namenode</h3>
<ul>
<li>Accountable for data locality and file system global namespace</li>
<li>Daemon on a dedicated server</li>
<li>Hosts metadata, create, remove, move files and folders</li>
<li>Knows nodes wich own the parts of a file</li>
<li>Needs to be replicated and secured (loss of metadata = loss of all
data)</li>
</ul>
</div><div class="column" style="width:40%;">
<h3 id="datanode">Datanode</h3>
<ul>
<li>Stores and loads data blocks</li>
<li>Daemon on every worker nodes</li>
<li>Reading and writing of data</li>
<li>Creation and Deletion of blocks</li>
</ul>
</div>
</div>
</section>
<section id="hdfs-architecture" class="slide level2">
<h2>HDFS Architecture</h2>
<p><img
data-src="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png" /></p>
</section>
<section id="quizz-1" class="slide level2">
<h2>Quizz</h2>
<p>What means HDFS?</p>
<ul>
<li>Answer A: Hadoop Distributed Functional Services</li>
<li>Answer B: Hadoop Delayed File System</li>
<li>Answer C: Hadoop Distributed File System</li>
<li>Answer D: Hadoop Delayed Functional Services</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_49">Answer link</a>
<em>Key: td</em></p>
</section></section>
<section>
<section id="map-reduce" class="title-slide slide level1">
<h1>Map Reduce</h1>

</section>
<section id="map-reduce-basics" class="slide level2">
<h2>Map Reduce Basics</h2>
<ul>
<li><strong>Functional</strong> language concept</li>
<li>Heavily used by Google for <strong>WWW indexing</strong></li>
<li><strong>Colocate</strong> data and processing (with Hadoop and
alikes)</li>
<li>Automatic process <strong>distribution</strong> on pieces of data
(eager distribution)</li>
<li>Optimized for fast processing of <strong>huge datasets</strong></li>
<li><strong>Fault tolerant</strong>:
<ul>
<li>Data is replicated,</li>
<li>Individual tasks can be restarted anywhere</li>
</ul></li>
</ul>
</section>
<section id="wordcount-1.-storage" class="slide level2">
<h2>Wordcount (1. storage)</h2>
<p><img data-src="images/Wordcount1.png" style="background:white" /></p>
</section>
<section id="wordcount-2.-split" class="slide level2">
<h2>Wordcount (2. split)</h2>
<p><img data-src="images/Wordcount2.png" style="background:white" /></p>
</section>
<section id="wordcount-3.-map" class="slide level2">
<h2>Wordcount (3. map)</h2>
<p><img data-src="images/Wordcount3.png" style="background:white" /></p>
</section>
<section id="wordcount-4.-shuffle" class="slide level2">
<h2>Wordcount (4. shuffle)</h2>
<p><img data-src="images/Wordcount4.png" style="background:white" /></p>
</section>
<section id="wordcount-5.-reduce" class="slide level2">
<h2>Wordcount (5. reduce)</h2>
<p><img data-src="images/Wordcount5.png" style="background:white" /></p>
</section>
<section id="wordcount-6.-result" class="slide level2">
<h2>Wordcount (6. result)</h2>
<p><img data-src="images/Wordcount6.png" style="background:white" /></p>
</section>
<section id="yarn" class="slide level2">
<h2>YaRN</h2>
<ul>
<li>Yet Another Resource Negociator…</li>
<li>Introduced in Hadoop v2</li>
<li>Separation between
<ul>
<li>Resources scheduling and cluster state</li>
<li>Job execution and distribution</li>
</ul></li>
</ul>
<p><img data-src="images/YARN.png" style="width:40.0%" /> <img
data-src="https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif"
style="width:40.0%" /></p>
</section>
<section id="quizz-2" class="slide level2">
<h2>Quizz</h2>
<p>What is the magical hidden step of distributed Map Reduce?</p>
<ul>
<li>Answer A: Map</li>
<li>Answer B: Reduce</li>
<li>Answer C: Shuffle</li>
<li>Answer D: Split</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_378">Answer link</a>
<em>Key: ep</em></p>
</section></section>
<section>
<section id="datalakes" class="title-slide slide level1">
<h1>Datalakes</h1>

</section>
<section id="toward-a-new-data-management-model" class="slide level2">
<h2>Toward a new data management model</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="process-centric">Process centric</h3>
<ul>
<li>Structured Data</li>
<li>Internal sources</li>
<li>Important data only</li>
<li>Multiple copies</li>
</ul>
<p><img data-src="images/ProcessCentric.png" style="height:25.0%" /></p>
</div><div class="column" style="width:50%;">
<h3 id="data-centric">Data centric</h3>
<ul>
<li>Multiple types (structured, semi-structured, unstructured)</li>
<li>Multiple sources (internal, external)</li>
<li>Everything</li>
<li>One copy</li>
</ul>
<p><img data-src="images/DataCentric.png" style="height:25.0%" /></p>
</div>
</div>
</section>
<section id="host-and-process-different-kind-of-data"
class="slide level2">
<h2>Host and process different kind of data</h2>
<p><img data-src="images/Datalake1.png" style="width:60.0%" /></p>
</section>
<section id="typical-architecture" class="slide level2">
<h2>Typical Architecture</h2>
<figure>
<img data-src="images/AzureDatalake.png" style="width:80.0%"
alt="Enterprise data lake reference architecture" />
<figcaption aria-hidden="true">Enterprise data lake reference
architecture</figcaption>
</figure>
</section>
<section id="cnes-datalake-infrastructure-example" class="slide level2">
<h2>CNES Datalake infrastructure example</h2>
<p><img data-src="images/CNESDatalake.png" style="width:50.0%" /></p>
</section>
<section id="quizz-3" class="slide level2">
<h2>Quizz</h2>
<p>What is the goal of a Datalake?</p>
<ul>
<li>Answer A: Host structured and filtered Data</li>
<li>Answer B: Host any kind of Data, at any stages of processing</li>
<li>Answer C: Standardizing Data structure</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_816">Answer link</a>
<em>Key: nv</em></p>
</section></section>
<section>
<section id="data-pipelines-and-associated-tools"
class="title-slide slide level1">
<h1>Data pipelines and associated tools</h1>

</section>
<section id="data-manipulation-is-complex" class="slide level2">
<h2>Data manipulation is complex</h2>
<p>You won’t usually achieve what you want with a single MapReduce or
Spark job.</p>
<p>Let’s say you want to train a ML model every time a text file is
updated on a website and evaluate it next.</p>
<p>You’ll need to:</p>
<div>
<ul>
<li class="fragment">Periodically poll the website for new data</li>
<li class="fragment">Launch your model training when new text file is
availaible</li>
<li class="fragment">Evaluate your new model on a reference dataset</li>
<li class="fragment">Push the evaluation result somewhere you can see
it</li>
</ul>
</div>
</section>
<section id="processing-pipelines" class="slide level2">
<h2>Processing pipelines</h2>
<p>This is called a Pipeline or a workflow.</p>
<p>It mainly means chaining tasks or jobs together to automatically
produce a result from an input.</p>
<p>Tasks are typically either:</p>
<ul>
<li>Triggered based on a date, periodicity (like Linux crontab for those
who knows).</li>
<li>Triggered by an external event: data availability.</li>
<li>Triggered by the end of the previous task or tasks.</li>
</ul>
<p>It is usually represented by Direct Acyclic Graphs (DAGs).</p>
</section>
<section id="example-in-satellite-ground-segment" class="slide level2">
<h2>Example in Satellite ground segment</h2>
<figure>
<img data-src="images/Iota2Pipeline.png" alt="Iota2 Pipeline" />
<figcaption aria-hidden="true">Iota2 Pipeline</figcaption>
</figure>
</section>
<section id="some-tools" class="slide level2">
<h2>Some tools</h2>
<figure>
<img data-src="images/demo_graph_view.png" alt="Airflow" />
<figcaption aria-hidden="true">Airflow</figcaption>
</figure>
<p>Plenty others from Apache or in Python ecosystem.</p>
</section></section>
<section>
<section id="hpc-platforms" class="title-slide slide level1">
<h1>HPC Platforms</h1>

</section>
<section id="overview-and-use-cases" class="slide level2">
<h2>Overview and Use cases</h2>
<div class="columns">
<div class="column" style="width:40%;">
<blockquote>
<p>HPC = High Performance Computing</p>
</blockquote>
<ul>
<li>HPC were built to solve compute bound problems</li>
<li>Some early fields of research:
<ul>
<li>Weather forecasting</li>
<li>Atmospheric and climate research</li>
<li>Rockets and Aeronautics design</li>
<li>Computational Fluid Dynamics in general</li>
</ul></li>
<li>High performance infrastructure: compute, CPU, storage, Network</li>
</ul>
</div><div class="column" style="width:60%;">
<iframe src="https://player.vimeo.com/video/300943265?h=ef84e12ec0" width="640" height="362" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen>
</iframe>
<p>
<a href="https://vimeo.com/300943265">Current speed in eNATL60
simulation with explicit tidal motion.</a> from
<a href="https://vimeo.com/oceannumerique">Océan Numérique</a> on
<a href="https://vimeo.com">Vimeo</a>.
</p>
<ul>
<li>number of processors in parallel required: 18000</li>
<li>Model time step: 40s</li>
<li>Model integration speed: 45 minutes for 1 model day</li>
<li>40 million cpu-hour allocation</li>
</ul>
</div>
</div>
</section>
<section id="cnes-typical-use-cases-1" class="slide level2">
<h2>CNES typical use cases (1)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="rd-studies-upstream-research">R&amp;D, Studies, upstream
research</h3>
<ul>
<li>Launchers (combustion, structure)</li>
<li>Flight dynamics, orbitography</li>
<li>Sensor data simulation</li>
<li>Satellite structure and materials</li>
<li>Technical domain: MPI, HTC, Big Data, AI</li>
</ul>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="images/HPCUpstream.png" alt="HPC Upstream" />
<figcaption aria-hidden="true">HPC Upstream</figcaption>
</figure>
</div>
</div>
</section>
<section id="cnes-typical-use-cases-2" class="slide level2">
<h2>CNES typical use cases (2)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<figure>
<img data-src="images/HPCProduction.png" alt="HPC production" />
<figcaption aria-hidden="true">HPC production</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<h3 id="data-production-and-diffusion">Data production and
diffusion</h3>
<ul>
<li>Continuous data production (L0 –&gt; L2)</li>
<li>Data portals, catalogs</li>
<li>Processing or reprocessing campains</li>
<li>Technical Domain: HTC</li>
<li>CNES Projects: SWOT, THEIA, SWH, SSALTO, PEPS</li>
</ul>
</div>
</div>
</section>
<section id="cnes-typical-use-cases-3" class="slide level2">
<h2>CNES typical use cases (3)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="data-analysis-dowstream-research">Data analysis, dowstream
research</h3>
<ul>
<li>Scientific studies on data prodcuts</li>
<li>Multi temporal or cross domain analysis</li>
<li>EO or astronomical Data</li>
<li>Technical Domain: HTC, Big Data, AI</li>
<li>CNES labs or projects : CESBIO, LEGOS, AI4Geo, EOLab</li>
</ul>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="images/HPCDownstream.png" alt="HPC downstream" />
<figcaption aria-hidden="true">HPC downstream</figcaption>
</figure>
</div>
</div>
</section>
<section id="architecture-big-picture" class="slide level2">
<h2>Architecture, big picture</h2>
<figure>
<img
data-src="https://www.marquette.edu/high-performance-computing/images/architecture.png"
style="width:50.0%" alt="HPC Architecture" />
<figcaption aria-hidden="true">HPC Architecture</figcaption>
</figure>
<p>Several things: Login nodes, Admin/Scheduler nodes, Compute
resources, Parallel FS, RMDA Network</p>
</section>
<section id="job-scheduler" class="slide level2">
<h2>Job scheduler</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Job Queuing System</li>
<li>Job = Resources, Walltime, Queue, Account, etc.</li>
<li>Resources management and scheduling</li>
<li>Priority, fairshare partition, QoS</li>
<li>SLURM, PBS, SGE, LSF, etc.</li>
</ul>
<figure>
<img data-src="images/HPCScheduler.png" alt="HPC Scheduler" />
<figcaption aria-hidden="true">HPC Scheduler</figcaption>
</figure>
</div><div class="column" style="width:50%;">
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --job-name=serial_job_test    # Job name</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --ntasks=1                    # Run on a single CPU</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --mem=1gb                     # Job memory request</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --time=00:05:00               # Time limit hrs:min:sec</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#SBATCH --output=serial_test_%j.log   # Standard output and error log</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="ex">module</span> load python</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> /data/training/SLURM/plot_template.py</span></code></pre></div>
</div>
</div>
</section>
<section id="high-performance-storage" class="slide level2">
<h2>High Performance Storage</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>POSIX file system</li>
<li>Usually based on powerfull SAN storage infrastructure</li>
<li>High performance and capacity: millions IO/s, hundreds GB/s,
hundreds PB capacity.</li>
<li>Spectrum Scale (GPFS) and Lustre</li>
<li>Other players: WekaIO, BeeGFS</li>
</ul>
</div><div class="column" style="width:50%;">
<figure>
<img data-src="images/GPFSHALArchitecture.png" style="height:50.0%"
alt="HAL GPFS" />
<figcaption aria-hidden="true">HAL GPFS</figcaption>
</figure>
</div>
</div>
</section>
<section id="software-technologies" class="slide level2">
<h2>Software technologies</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li>Classical HPC: C and Fortran
<ul>
<li>Compiled languages, hardware optimized</li>
<li>MPI &amp; OpenMP</li>
<li>CUDA, OpenACC</li>
</ul></li>
<li>More and More: Python, Julia
<ul>
<li>Interpreted Languages, easyer to use</li>
<li>Lots of performant libraries to reuse (e.g. Numpy, Scipy, Pandas,
etc.)</li>
<li>Parallel and distributed computations:
<ul>
<li>Multiprocessing</li>
<li>MPI4Py : Python over MPI</li>
<li>Dask, Ray, etc.</li>
</ul></li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<figure>
<img data-src="images/mpimultistampede70pct.png" alt="MPI Code" />
<figcaption aria-hidden="true">MPI Code</figcaption>
</figure>
</div>
</div>
</section></section>
<section>
<section
id="from-hpc-to-big-data-to-cloud-and-high-performance-data-analytics"
class="title-slide slide level1">
<h1>From HPC to Big Data to Cloud and High Performance Data
Analytics</h1>

</section>
<section id="hpc-platform-story-and-use-case" class="slide level2">
<h2>HPC platform, story and use case</h2>
<div class="columns">
<div class="column" style="width:50%;">
<blockquote>
<p>HPC = High Performance Computing</p>
</blockquote>
<ul>
<li>Firsts HPC platforms built in the 1960s</li>
<li>Mainly compute bounds algorithms</li>
<li>At first for Weather forcasting and Aerodynamic research</li>
<li>Structure modeling and fluid mecanics by discretization</li>
<li>Needs (needed?) high performance hardware (network, CPUs,
storage)</li>
<li>Compute and storage are separated</li>
<li>Uses a resource scheduler</li>
</ul>
</div><div class="column" style="width:50%;">
<figure>
<img
data-src="http://www.idris.fr/media/images/jean-zay-annonce-01.jpg?id=web%3Aeng%3Ajean-zay%3Acpu%3Ajean-zay-cpu-hw-eng"
alt="Jean-Zay supercomputer" />
<figcaption aria-hidden="true">Jean-Zay supercomputer</figcaption>
</figure>
</div>
</div>
</section>
<section id="top500" class="slide level2">
<h2>TOP500</h2>
<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 24%" />
<col style="width: 26%" />
<col style="width: 18%" />
</colgroup>
<thead>
<tr class="header">
<th>Rank</th>
<th>System</th>
<th>Cores</th>
<th>Rmax (TFlop/s)</th>
<th>Rpeak (PFlop/s)</th>
<th>Power (kW)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Frontier - United States</td>
<td>8,699,904</td>
<td>1,194.00</td>
<td>1,679.82</td>
<td>22,703</td>
</tr>
<tr class="even">
<td>2</td>
<td>Aurora - United States</td>
<td>4,742,808</td>
<td>585.34</td>
<td>1,059.33</td>
<td>24,687</td>
</tr>
<tr class="odd">
<td>4</td>
<td>Supercomputer Fugaku - Japan</td>
<td>7,630,848</td>
<td>442.01</td>
<td>537.21</td>
<td>29,899</td>
</tr>
<tr class="even">
<td>5</td>
<td>LUMI - Finland</td>
<td>2,752,704</td>
<td>2379.70</td>
<td>531.51</td>
<td>7,107</td>
</tr>
<tr class="odd">
<td>17</td>
<td>Adastra - France</td>
<td>319,072</td>
<td>46.10</td>
<td>61.61</td>
<td>921</td>
</tr>
<tr class="even">
<td>167</td>
<td>Jean Zay - France</td>
<td>93,960</td>
<td>4.48</td>
<td>7.35</td>
<td></td>
</tr>
</tbody>
</table>
<p><a href="https://top500.org/lists/top500/2023/11/">Top 500 (november
2023)</a></p>
</section>
<section id="big-data-and-hadoop" class="slide level2">
<h2>Big Data and Hadoop</h2>
<ul>
<li>First platforms in the 2000’s</li>
<li>Mainly data bound algorithms</li>
<li>Limitation in standard ethernet network performances = data
locality</li>
<li>At first for web indexing, or large amount of textual or tabular
data analysis</li>
<li>Web giant problem, then banking or IT stuf</li>
<li>Use commodity hardware</li>
<li>Compute and storage colocated</li>
</ul>
</section>
<section id="hpda-convergence" class="slide level2">
<h2>HPDA convergence</h2>
<p><img data-src="images/HPDA.png" style="width:50.0%" /></p>
<ul>
<li>Hadoop world step towards HPC: YaRN, equivalent to HPC resources
scheduler</li>
<li>HPC step towards Big Data: hardware not so specialized</li>
<li>Hadoop big limitation: non standard File System and compute and
storage colocation</li>
<li>HPC big limitation: storage can be difficult to scale</li>
</ul>
</section>
<section id="cloud-computing-basics" class="slide level2">
<h2>Cloud computing basics</h2>
<p>Hence the cloud computing model…</p>
<ul>
<li>Compute resources separated from storage (but proximity is key)</li>
<li>Can host anything, at first not compute oriented</li>
<li>Object store model: Software Defined Storage as HDFS, specific
interface (S3)</li>
<li>Horizontal scalability of compute AND storage</li>
<li>Resources on demand, mutualized between millions of users</li>
<li>Infinite resources like for user</li>
</ul>
</section>
<section id="distributed-programming-hadoop-vs-hpc-vs-cloud"
class="slide level2">
<h2>Distributed programming: Hadoop vs HPC vs Cloud</h2>
<div class="columns">
<div class="column" style="width:33%;">
<h3 id="hadoop-1">Hadoop</h3>
<ul>
<li>Data bound algorithms</li>
<li>Statistics</li>
<li>Big volumes in input</li>
<li>Often small outputs</li>
<li>Can be used for computing problems, but not physical simulation</li>
</ul>
</div><div class="column" style="width:33%;">
<h3 id="hpc-mpi">HPC (MPI)</h3>
<ul>
<li>Compute bound algorithms</li>
<li>Small or medium amount of inputs,</li>
<li>Medium or big outputs (big simulations)</li>
<li>Can be used for data processing too (Dask)</li>
</ul>
</div><div class="column" style="width:33%;">
<h3 id="cloud">Cloud</h3>
<ul>
<li>Anything: services, storage bound, compute bound</li>
<li>Object store limitations for some HPC workflow</li>
<li>Or not anymore: HPC as a Service</li>
<li>Big Data as a Service too…</li>
</ul>
</div>
</div>
</section>
<section id="machine-learning-computations" class="slide level2">
<h2>Machine Learning Computations</h2>
<h3 id="machine-learning">Machine learning</h3>
<ul>
<li>Either lots of data in inputs</li>
<li>Or lots of models to train (hyperparameter search)</li>
<li>And of course data preprocessing</li>
<li>Big Data or HPC or Cloud</li>
</ul>
<h3 id="gpgpu">GPGPU</h3>
<ul>
<li>Specific hardware (expensive)</li>
<li>Really efficient for Deep Learning algorithms</li>
<li>Image processing, Language processing</li>
</ul>
</section>
<section id="quizz-4" class="slide level2">
<h2>Quizz</h2>
<p>How Big Data processing differs from classical HPC (multiple
choices)?</p>
<ul>
<li>Answer A: It is compute bound</li>
<li>Answer B: It is data bound</li>
<li>Answer C: It uses specialized hardware</li>
<li>Answer D: It uses commodity hardware</li>
<li>Answer E: It is fault tolerant</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_50">Answer link</a>
<em>Key: ex</em></p>
</section></section>
<section>
<section id="bi-vs-big-data" class="title-slide slide level1">
<h1>BI vs Big Data</h1>

</section>
<section id="business-intelligence" class="slide level2">
<h2>Business Intelligence</h2>
<blockquote>
<p>Business intelligence (BI) comprises the strategies and technologies
used by enterprises for the data analysis of business information.</p>
<p>BI technologies provide historical, current, and predictive views of
business operations.</p>
</blockquote>
<p><em>Wikipedia</em></p>
<p>Business Intelligence <em>can</em> use Big Data ecosystems, but is
more commonly considered something different.</p>
<p><a
href="https://medium.com/doctolib/data-engineers-are-no-longer-data-folks-d10d44712580">https://medium.com/doctolib/data-engineers-are-no-longer-data-folks-d10d44712580</a>
<a
href="https://alphalyr.fr/blog/difference-bi-business-intelligence-big-data/">https://alphalyr.fr/blog/difference-bi-business-intelligence-big-data/</a></p>
</section>
<section id="classical-bi-key-points" class="slide level2">
<h2>Classical BI key points</h2>
<ul>
<li>Build data systems from Business questions</li>
<li>KPI and business decisions oriented</li>
<li>Data warehouse, mainframe = Big server with closed technology</li>
<li>Use structured data, like SQL databases,</li>
<li>Oriented towards Data Value</li>
</ul>
</section>
<section id="big-data-key-points" class="slide level2">
<h2>Big Data key points</h2>
<ul>
<li>Find insights from the data systems,</li>
<li>KPI and business of course, but many more use cases</li>
<li>Distributed architecture, lot of Open Source</li>
<li>Different toolset (Hadoop, Python),</li>
<li>Every data flavor, keep anything!</li>
<li>Data Volume, Variety, Velocity</li>
</ul>
</section></section>
<section>
<section id="hadoop-and-big-data-legacy"
class="title-slide slide level1">
<h1>Hadoop and Big Data legacy</h1>

</section>
<section id="is-hadoop-dead" class="slide level2">
<h2>Is Hadoop dead?</h2>
<p>Not quite yet. Still <strong>used in many places</strong></p>
<div class="fragment">
<p>It grew up with <strong>web giants</strong>, producing a really rich
and <strong>open source</strong> ecosystem</p>
</div>
<div class="fragment">
<p>But clearly the two main components (HDFS and MapReduce) are now
<strong>deprecated</strong></p>
</div>
<div class="fragment">
<p>And have paved the way to better alternatives</p>
</div>
</section>
<section id="future-of-big-data" class="slide level2">
<h2>Future of Big Data</h2>
<p>Infrastructure: Private or public cloud, and HPC(DA) in some
cases.</p>
<div class="fragment">
<p>HDFS? Object Storage!</p>
</div>
<div class="fragment">
<p>MapReduce? Spark, Dask.</p>
</div>
<div class="fragment">
<p>Chunked file format (SequenceFile)? Parquet, Zarr, Cloud optimized
Geotiff.</p>
</div>
<div class="fragment">
<p>YaRN? HPC job scheduler, or Kubernetes</p>
</div>
<div class="fragment">
<h3 id="cloud-computing">Cloud Computing</h3>
</div>
</section>
<section id="quizz-5" class="slide level2">
<h2>Quizz</h2>
<p>What technologies are replacing Hadoop ecosystem (multiple
choices)?</p>
<ul>
<li>Answer A: Map Reduce</li>
<li>Answer B: MPI (Message Passing Interface)</li>
<li>Answer C: Spark</li>
<li>Answer D: Cloud computing and object storage</li>
</ul>
<figure>
<img data-src="" alt="Answer" />
<figcaption aria-hidden="true">Answer</figcaption>
</figure>
<p><a href="https://toreply.univ-lille.fr/reponse_561">Answer link</a>
<em>Key: pc</em></p>
</section></section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@^4//dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="https://unpkg.com/reveal.js@^4//plugin/notes/notes.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/search/search.js"></script>
  <script src="https://unpkg.com/reveal.js@^4//plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

       // Parallax background image
       parallaxBackgroundImage: 'images/background-logo.png', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1800,

        height: 900,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.1,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
